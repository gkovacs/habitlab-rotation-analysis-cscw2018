{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import lzstring\n",
    "from collections import namedtuple, Counter\n",
    "import json\n",
    "from memoize import memoize\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# [num unique urls, num unique urls typed, total visits, total typed, first visit time, last visit time]\n",
    "domaininfo = namedtuple('domaininfo', ['num_unique_urls', 'num_unique_urls_typed', 'total_visits', 'total_typed', 'first_visit_time', 'last_visit_time'])\n",
    "\n",
    "decompressFromEncodedURIComponent = lzstring.LZString().decompressFromEncodedURIComponent\n",
    "\n",
    "#filepath = 'difficultyselectionexp_may31_11am.csv'\n",
    "filepath = 'data/difficultyselectionexp_june25_9pm.csv'\n",
    "reader = csv.DictReader(open(filepath))\n",
    "\n",
    "def extract_domain_visit_info(domain_visit_info_compressed):\n",
    "  domain_visit_info = json.loads(decompressFromEncodedURIComponent(domain_visit_info_compressed))\n",
    "  output = {}\n",
    "  for k,v in domain_visit_info.items():\n",
    "    linedata = domaininfo(*v)\n",
    "    output[k] = linedata\n",
    "  return output\n",
    "\n",
    "alldata = []\n",
    "\n",
    "for alldata_item in reader:\n",
    "  if alldata_item['selected_difficulty'] not in ['nothing', 'easy', 'medium', 'hard']:\n",
    "    continue\n",
    "  if alldata_item['domain_visit_info_compressed'] == None or len(alldata_item['domain_visit_info_compressed']) == 0:\n",
    "    continue\n",
    "  alldata_item['domain_visit_info'] = extract_domain_visit_info(alldata_item['domain_visit_info_compressed'])\n",
    "  alldata.append(alldata_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "#np.random.shuffle(alldata)\n",
    "training_data = alldata[:round(len(alldata)*0.8)]\n",
    "test_data = alldata[round(len(alldata)*0.8):]\n",
    "print(len(training_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_alldata(data):\n",
    "  return np.array([line['selected_difficulty'] for line in data])\n",
    "\n",
    "@memoize\n",
    "def get_most_common_label():\n",
    "  label_to_count = Counter()\n",
    "  for line in training_data:\n",
    "    label = line['selected_difficulty']\n",
    "    label_to_count[label] += 1\n",
    "  sorted_by_count = sorted(label_to_count.items(), key=lambda x: x[1], reverse=True)\n",
    "  return sorted_by_count[0][0]\n",
    "\n",
    "@memoize\n",
    "def get_most_visited_domains():\n",
    "  domain_to_num_visits = Counter()\n",
    "  for line in training_data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    for domain,info in domain_visit_info.items():\n",
    "      domain_to_num_visits[domain] += info.total_visits\n",
    "  sorted_by_num_visits = sorted(domain_to_num_visits.items(), key=lambda x: x[1], reverse=True)\n",
    "  return [x[0] for x in sorted_by_num_visits[:100]]\n",
    "\n",
    "cnt = 0\n",
    "@memoize\n",
    "def get_most_common_domains():\n",
    "  domain_to_num_visits = Counter()\n",
    "  for line in training_data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    for domain,info in domain_visit_info.items():\n",
    "      domain_to_num_visits[domain] += 1\n",
    "  sorted_by_num_visits = sorted(domain_to_num_visits.items(), key=lambda x: x[1], reverse=True)\n",
    "  return [x[0] for x in sorted_by_num_visits[:100]]\n",
    "\n",
    "def get_all_domains():\n",
    "  domain_to_num_visits = Counter()\n",
    "  for line in training_data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    for domain,info in domain_visit_info.items():\n",
    "      domain_to_num_visits[domain] += 1\n",
    "  sorted_by_num_visits = sorted(domain_to_num_visits.items(), key=lambda x: x[1], reverse=True)\n",
    "  return [x[0] for x in sorted_by_num_visits]\n",
    "\n",
    "\n",
    "\n",
    "def get_num_visits_for_domain(domain_visit_info, domain):\n",
    "  info = domain_visit_info.get(domain, None)\n",
    "  if info != None:\n",
    "    return info.total_visits\n",
    "  return 0\n",
    "\n",
    "def get_productivity():\n",
    "    with open ('domain_to_productivity.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data\n",
    "\n",
    "domain_to_productivity = get_productivity()\n",
    "\n",
    "def extract_features_for_user(domain_visit_info):\n",
    "  cnt = 0\n",
    "  domains = get_all_domains()\n",
    "  final_features = [0, 0, 0, 0, 0];\n",
    "  for x in domains:\n",
    "        if x in domain_to_productivity.keys():\n",
    "            final_features[domain_to_productivity[x] + 2] += get_num_visits_for_domain(domain_visit_info, x)\n",
    "    \n",
    "  #np.array([get_num_visits_for_domain(domain_visit_info, x) for x in domains])\n",
    "  if np.sum(final_features) >= 1:\n",
    "    final_features = np.divide(final_features, np.sum(final_features))\n",
    "  return final_features\n",
    "\n",
    "def extract_features_alldata(data):\n",
    "  output = []\n",
    "  for line in data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    features = extract_features_for_user(domain_visit_info)\n",
    "    output.append(features)\n",
    "  return np.array(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline classifier accuracy: 0.4186046511627907\n"
     ]
    }
   ],
   "source": [
    "def get_percent_correct(predicted_labels, actual_labels):\n",
    "  if len(predicted_labels) != len(actual_labels):\n",
    "    raise 'need predicted and actual labels to have same lengths'\n",
    "  total = len(actual_labels)\n",
    "  correct = 0\n",
    "  for p,a in zip(predicted_labels, actual_labels):\n",
    "    if p == a:\n",
    "      correct += 1\n",
    "  return correct / total\n",
    "\n",
    "def test_baseline_classifier():\n",
    "  most_common_label = get_most_common_label()\n",
    "  predictions = [most_common_label for line in test_data]\n",
    "  actual = extract_labels_alldata(test_data)\n",
    "  percent_correct = get_percent_correct(predictions, actual)\n",
    "  print('baseline classifier accuracy:', percent_correct)\n",
    "\n",
    "def test_classifier(clf,features_test, actual, str=None):\n",
    "  #actual = extract_labels_alldata(test_data)\n",
    "  #features_test = extract_features_alldata(test_data)\n",
    "  predictions = clf.predict(features_test)\n",
    "  percent_correct = get_percent_correct(predictions, actual)\n",
    "  return percent_correct\n",
    "\n",
    "def training_error_classifier(clf, str=None):\n",
    "  actual = extract_labels_alldata(training_data)\n",
    "  features_train = extract_features_alldata(training_data)\n",
    "  predictions = clf.predict(features_train)\n",
    "  percent_correct = get_percent_correct(predictions, actual)\n",
    "  print(str + ' classifier training accuracy:', round(percent_correct, 2))\n",
    "\n",
    "def to_int_categorical(dt):\n",
    "  # {'easy', 'hard', 'medium', 'nothing'}\n",
    "  cat_dt = []\n",
    "  for item in dt:\n",
    "    if item == 'nothing':\n",
    "      cat_dt.append(0)\n",
    "    elif item == 'easy':\n",
    "      cat_dt.append(1)\n",
    "    elif item == 'medium':\n",
    "      cat_dt.append(2)\n",
    "    else:\n",
    "      cat_dt.append(3)\n",
    "  return np.array(cat_dt)\n",
    "    \n",
    "test_baseline_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_train = extract_labels_alldata(training_data)\n",
    "features_train = extract_features_alldata(training_data)\n",
    "labels_test = extract_labels_alldata(test_data)\n",
    "features_test = extract_features_alldata(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifiers():\n",
    "    clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    RF = test_classifier(clf, features_test, labels_test, 'RF')\n",
    "\n",
    "    clf = KNeighborsClassifier(n_neighbors=3, p=1)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    KNN = test_classifier(clf, features_test, labels_test, 'KNN')\n",
    "    return [RF, KNN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3488372093023256, 0.43023255813953487]\n"
     ]
    }
   ],
   "source": [
    "print (classifiers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "\n",
    "labels_test = to_categorical(to_int_categorical(extract_labels_alldata(test_data)), num_classes=4)\n",
    "features_test = extract_features_alldata(test_data)\n",
    "\n",
    "labels_train = to_categorical(to_int_categorical(extract_labels_alldata(training_data)), num_classes=4)\n",
    "features_train = extract_features_alldata(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(300, activation='relu', input_dim=5, kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.001))\n",
    "    model.add(Dense(300, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.001))\n",
    "    model.add(Dense(300, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.001))\n",
    "    model.add(Dense(4, activation='softmax', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "    sgd = SGD(lr=0.05, decay=1e-3, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(features_train, labels_train,\n",
    "          epochs=500,\n",
    "          batch_size=32)\n",
    "    score = model.evaluate(features_test, labels_test, batch_size=32)\n",
    "\n",
    "    predictions = model.predict(features_test, batch_size=32)\n",
    "    \n",
    "    print(predictions)\n",
    "    print(labels_test)\n",
    "    print(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "346/346 [==============================] - 0s 800us/step - loss: 1.9650 - acc: 0.3728\n",
      "Epoch 2/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.9084 - acc: 0.4104\n",
      "Epoch 3/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.8902 - acc: 0.4104\n",
      "Epoch 4/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.8768 - acc: 0.4104\n",
      "Epoch 5/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.8662 - acc: 0.4220\n",
      "Epoch 6/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.8462 - acc: 0.4364\n",
      "Epoch 7/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.8313 - acc: 0.4306\n",
      "Epoch 8/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.8209 - acc: 0.4306\n",
      "Epoch 9/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.8087 - acc: 0.4335\n",
      "Epoch 10/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.7935 - acc: 0.4335\n",
      "Epoch 11/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.7841 - acc: 0.4393\n",
      "Epoch 12/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.7708 - acc: 0.4364\n",
      "Epoch 13/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.7630 - acc: 0.4335\n",
      "Epoch 14/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.7571 - acc: 0.4162\n",
      "Epoch 15/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.7470 - acc: 0.4364\n",
      "Epoch 16/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.7372 - acc: 0.4306\n",
      "Epoch 17/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.7268 - acc: 0.4335\n",
      "Epoch 18/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.7155 - acc: 0.4364\n",
      "Epoch 19/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.7118 - acc: 0.4451\n",
      "Epoch 20/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.7078 - acc: 0.4306\n",
      "Epoch 21/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.7014 - acc: 0.4335\n",
      "Epoch 22/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.6920 - acc: 0.4335\n",
      "Epoch 23/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.6806 - acc: 0.4277\n",
      "Epoch 24/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.6738 - acc: 0.4335\n",
      "Epoch 25/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.6632 - acc: 0.4335\n",
      "Epoch 26/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.6567 - acc: 0.4335\n",
      "Epoch 27/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.6539 - acc: 0.4162\n",
      "Epoch 28/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.6433 - acc: 0.4364\n",
      "Epoch 29/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.6404 - acc: 0.4393\n",
      "Epoch 30/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.6316 - acc: 0.4393\n",
      "Epoch 31/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.6229 - acc: 0.4393\n",
      "Epoch 32/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.6166 - acc: 0.4306\n",
      "Epoch 33/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.6124 - acc: 0.4306\n",
      "Epoch 34/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.6052 - acc: 0.4277\n",
      "Epoch 35/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.6039 - acc: 0.4191\n",
      "Epoch 36/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.5964 - acc: 0.4451\n",
      "Epoch 37/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.5895 - acc: 0.4306\n",
      "Epoch 38/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.5840 - acc: 0.4306\n",
      "Epoch 39/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.5790 - acc: 0.4335\n",
      "Epoch 40/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.5735 - acc: 0.4335\n",
      "Epoch 41/500\n",
      "346/346 [==============================] - 0s 102us/step - loss: 1.5716 - acc: 0.4306\n",
      "Epoch 42/500\n",
      "346/346 [==============================] - 0s 102us/step - loss: 1.5690 - acc: 0.4335\n",
      "Epoch 43/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.5661 - acc: 0.4451\n",
      "Epoch 44/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.5598 - acc: 0.4249\n",
      "Epoch 45/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.5530 - acc: 0.4335\n",
      "Epoch 46/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.5529 - acc: 0.4277\n",
      "Epoch 47/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.5416 - acc: 0.4422\n",
      "Epoch 48/500\n",
      "346/346 [==============================] - 0s 97us/step - loss: 1.5393 - acc: 0.4277\n",
      "Epoch 49/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.5390 - acc: 0.4364\n",
      "Epoch 50/500\n",
      "346/346 [==============================] - 0s 99us/step - loss: 1.5386 - acc: 0.4335\n",
      "Epoch 51/500\n",
      "346/346 [==============================] - 0s 99us/step - loss: 1.5287 - acc: 0.4393\n",
      "Epoch 52/500\n",
      "346/346 [==============================] - 0s 100us/step - loss: 1.5248 - acc: 0.4335\n",
      "Epoch 53/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.5193 - acc: 0.4393\n",
      "Epoch 54/500\n",
      "346/346 [==============================] - 0s 107us/step - loss: 1.5184 - acc: 0.4335\n",
      "Epoch 55/500\n",
      "346/346 [==============================] - 0s 102us/step - loss: 1.5151 - acc: 0.4451\n",
      "Epoch 56/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.5091 - acc: 0.4335\n",
      "Epoch 57/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.5064 - acc: 0.4393\n",
      "Epoch 58/500\n",
      "346/346 [==============================] - 0s 99us/step - loss: 1.5078 - acc: 0.4364\n",
      "Epoch 59/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.5007 - acc: 0.4335\n",
      "Epoch 60/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.4988 - acc: 0.4393\n",
      "Epoch 61/500\n",
      "346/346 [==============================] - 0s 101us/step - loss: 1.5020 - acc: 0.4191\n",
      "Epoch 62/500\n",
      "346/346 [==============================] - 0s 102us/step - loss: 1.4895 - acc: 0.4451\n",
      "Epoch 63/500\n",
      "346/346 [==============================] - 0s 99us/step - loss: 1.4896 - acc: 0.4451\n",
      "Epoch 64/500\n",
      "346/346 [==============================] - 0s 111us/step - loss: 1.4875 - acc: 0.4364\n",
      "Epoch 65/500\n",
      "346/346 [==============================] - 0s 102us/step - loss: 1.4828 - acc: 0.4306\n",
      "Epoch 66/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.4795 - acc: 0.4335\n",
      "Epoch 67/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.4784 - acc: 0.4393\n",
      "Epoch 68/500\n",
      "346/346 [==============================] - 0s 100us/step - loss: 1.4764 - acc: 0.4364\n",
      "Epoch 69/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.4741 - acc: 0.4422\n",
      "Epoch 70/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.4692 - acc: 0.4451\n",
      "Epoch 71/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.4677 - acc: 0.4509\n",
      "Epoch 72/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.4631 - acc: 0.4393\n",
      "Epoch 73/500\n",
      "346/346 [==============================] - 0s 101us/step - loss: 1.4648 - acc: 0.4335\n",
      "Epoch 74/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.4630 - acc: 0.4393\n",
      "Epoch 75/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.4643 - acc: 0.4249\n",
      "Epoch 76/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.4563 - acc: 0.4364\n",
      "Epoch 77/500\n",
      "346/346 [==============================] - 0s 100us/step - loss: 1.4507 - acc: 0.4393\n",
      "Epoch 78/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.4486 - acc: 0.4422\n",
      "Epoch 79/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.4481 - acc: 0.4393\n",
      "Epoch 80/500\n",
      "346/346 [==============================] - 0s 97us/step - loss: 1.4461 - acc: 0.4393\n",
      "Epoch 81/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.4431 - acc: 0.4364\n",
      "Epoch 82/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.4489 - acc: 0.4335\n",
      "Epoch 83/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.4419 - acc: 0.4480\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 89us/step - loss: 1.4363 - acc: 0.4393\n",
      "Epoch 85/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.4369 - acc: 0.4422\n",
      "Epoch 86/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.4344 - acc: 0.4393\n",
      "Epoch 87/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.4344 - acc: 0.4451\n",
      "Epoch 88/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.4330 - acc: 0.4451\n",
      "Epoch 89/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.4291 - acc: 0.4422\n",
      "Epoch 90/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.4246 - acc: 0.4509\n",
      "Epoch 91/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.4239 - acc: 0.4422\n",
      "Epoch 92/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.4218 - acc: 0.4393\n",
      "Epoch 93/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.4198 - acc: 0.4393\n",
      "Epoch 94/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.4205 - acc: 0.4364\n",
      "Epoch 95/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.4158 - acc: 0.4393\n",
      "Epoch 96/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.4179 - acc: 0.4364\n",
      "Epoch 97/500\n",
      "346/346 [==============================] - 0s 101us/step - loss: 1.4141 - acc: 0.4451\n",
      "Epoch 98/500\n",
      "346/346 [==============================] - 0s 102us/step - loss: 1.4124 - acc: 0.4451\n",
      "Epoch 99/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.4143 - acc: 0.4451\n",
      "Epoch 100/500\n",
      "346/346 [==============================] - 0s 99us/step - loss: 1.4182 - acc: 0.4422\n",
      "Epoch 101/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.4103 - acc: 0.4249\n",
      "Epoch 102/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.4162 - acc: 0.4364\n",
      "Epoch 103/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.4074 - acc: 0.4364\n",
      "Epoch 104/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.4036 - acc: 0.4422\n",
      "Epoch 105/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.4028 - acc: 0.4451\n",
      "Epoch 106/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3996 - acc: 0.4422\n",
      "Epoch 107/500\n",
      "346/346 [==============================] - 0s 101us/step - loss: 1.3988 - acc: 0.4422\n",
      "Epoch 108/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3969 - acc: 0.4364\n",
      "Epoch 109/500\n",
      "346/346 [==============================] - 0s 99us/step - loss: 1.3955 - acc: 0.4364\n",
      "Epoch 110/500\n",
      "346/346 [==============================] - 0s 97us/step - loss: 1.3979 - acc: 0.4422\n",
      "Epoch 111/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.3925 - acc: 0.4451\n",
      "Epoch 112/500\n",
      "346/346 [==============================] - 0s 97us/step - loss: 1.3928 - acc: 0.4480\n",
      "Epoch 113/500\n",
      "346/346 [==============================] - 0s 99us/step - loss: 1.3917 - acc: 0.4422\n",
      "Epoch 114/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3887 - acc: 0.4422\n",
      "Epoch 115/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3862 - acc: 0.4335\n",
      "Epoch 116/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.3896 - acc: 0.4480\n",
      "Epoch 117/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3869 - acc: 0.4422\n",
      "Epoch 118/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.3905 - acc: 0.4393\n",
      "Epoch 119/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.3895 - acc: 0.4422\n",
      "Epoch 120/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.3848 - acc: 0.4451\n",
      "Epoch 121/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3815 - acc: 0.4393\n",
      "Epoch 122/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.3798 - acc: 0.4364\n",
      "Epoch 123/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3803 - acc: 0.4364\n",
      "Epoch 124/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.3797 - acc: 0.4393\n",
      "Epoch 125/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.3776 - acc: 0.4451\n",
      "Epoch 126/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3738 - acc: 0.4422\n",
      "Epoch 127/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3751 - acc: 0.4422\n",
      "Epoch 128/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.3739 - acc: 0.4422\n",
      "Epoch 129/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3785 - acc: 0.4335\n",
      "Epoch 130/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3723 - acc: 0.4393\n",
      "Epoch 131/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3760 - acc: 0.4364\n",
      "Epoch 132/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.3702 - acc: 0.4422\n",
      "Epoch 133/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3691 - acc: 0.4393\n",
      "Epoch 134/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.3691 - acc: 0.4422\n",
      "Epoch 135/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.3668 - acc: 0.4451\n",
      "Epoch 136/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.3708 - acc: 0.4364\n",
      "Epoch 137/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.3648 - acc: 0.4422\n",
      "Epoch 138/500\n",
      "346/346 [==============================] - 0s 107us/step - loss: 1.3646 - acc: 0.4422\n",
      "Epoch 139/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3635 - acc: 0.4480\n",
      "Epoch 140/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3617 - acc: 0.4451\n",
      "Epoch 141/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3609 - acc: 0.4451\n",
      "Epoch 142/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3593 - acc: 0.4509\n",
      "Epoch 143/500\n",
      "346/346 [==============================] - 0s 104us/step - loss: 1.3590 - acc: 0.4422\n",
      "Epoch 144/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.3600 - acc: 0.4393\n",
      "Epoch 145/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.3596 - acc: 0.4451\n",
      "Epoch 146/500\n",
      "346/346 [==============================] - 0s 101us/step - loss: 1.3583 - acc: 0.4451\n",
      "Epoch 147/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.3593 - acc: 0.4509\n",
      "Epoch 148/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3549 - acc: 0.4480\n",
      "Epoch 149/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3563 - acc: 0.4364\n",
      "Epoch 150/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3590 - acc: 0.4364\n",
      "Epoch 151/500\n",
      "346/346 [==============================] - 0s 97us/step - loss: 1.3525 - acc: 0.4393\n",
      "Epoch 152/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3554 - acc: 0.4538\n",
      "Epoch 153/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3551 - acc: 0.4480\n",
      "Epoch 154/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3539 - acc: 0.4451\n",
      "Epoch 155/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3537 - acc: 0.4393\n",
      "Epoch 156/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3508 - acc: 0.4335\n",
      "Epoch 157/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3505 - acc: 0.4422\n",
      "Epoch 158/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3484 - acc: 0.4451\n",
      "Epoch 159/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3485 - acc: 0.4451\n",
      "Epoch 160/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3495 - acc: 0.4451\n",
      "Epoch 161/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3483 - acc: 0.4451\n",
      "Epoch 162/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3455 - acc: 0.4480\n",
      "Epoch 163/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3441 - acc: 0.4422\n",
      "Epoch 164/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3485 - acc: 0.4422\n",
      "Epoch 165/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3511 - acc: 0.4306\n",
      "Epoch 166/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.3412 - acc: 0.4480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.3427 - acc: 0.4509\n",
      "Epoch 168/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3451 - acc: 0.4509\n",
      "Epoch 169/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3493 - acc: 0.4277\n",
      "Epoch 170/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3460 - acc: 0.4393\n",
      "Epoch 171/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.3391 - acc: 0.4566\n",
      "Epoch 172/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3422 - acc: 0.4335\n",
      "Epoch 173/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3383 - acc: 0.4480\n",
      "Epoch 174/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.3384 - acc: 0.4364\n",
      "Epoch 175/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3390 - acc: 0.4451\n",
      "Epoch 176/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3353 - acc: 0.4393\n",
      "Epoch 177/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3420 - acc: 0.4422\n",
      "Epoch 178/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3383 - acc: 0.4393\n",
      "Epoch 179/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3347 - acc: 0.4480\n",
      "Epoch 180/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3376 - acc: 0.4480\n",
      "Epoch 181/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3399 - acc: 0.4393\n",
      "Epoch 182/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3329 - acc: 0.4538\n",
      "Epoch 183/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3370 - acc: 0.4451\n",
      "Epoch 184/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3356 - acc: 0.4364\n",
      "Epoch 185/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.3350 - acc: 0.4480\n",
      "Epoch 186/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3318 - acc: 0.4451\n",
      "Epoch 187/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3320 - acc: 0.4509\n",
      "Epoch 188/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3299 - acc: 0.4509\n",
      "Epoch 189/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3305 - acc: 0.4451\n",
      "Epoch 190/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3290 - acc: 0.4422\n",
      "Epoch 191/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3340 - acc: 0.4509\n",
      "Epoch 192/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3290 - acc: 0.4509\n",
      "Epoch 193/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3286 - acc: 0.4566\n",
      "Epoch 194/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3287 - acc: 0.4480\n",
      "Epoch 195/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3315 - acc: 0.4364\n",
      "Epoch 196/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3295 - acc: 0.4422\n",
      "Epoch 197/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3295 - acc: 0.4595\n",
      "Epoch 198/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.3271 - acc: 0.4480\n",
      "Epoch 199/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.3249 - acc: 0.4538\n",
      "Epoch 200/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3251 - acc: 0.4509\n",
      "Epoch 201/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3252 - acc: 0.4451\n",
      "Epoch 202/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3266 - acc: 0.4480\n",
      "Epoch 203/500\n",
      "346/346 [==============================] - 0s 82us/step - loss: 1.3230 - acc: 0.4509\n",
      "Epoch 204/500\n",
      "346/346 [==============================] - 0s 82us/step - loss: 1.3239 - acc: 0.4451\n",
      "Epoch 205/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3225 - acc: 0.4422\n",
      "Epoch 206/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3217 - acc: 0.4451\n",
      "Epoch 207/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.3252 - acc: 0.4364\n",
      "Epoch 208/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3217 - acc: 0.4451\n",
      "Epoch 209/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3249 - acc: 0.4451\n",
      "Epoch 210/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3206 - acc: 0.4480\n",
      "Epoch 211/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3220 - acc: 0.4509\n",
      "Epoch 212/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3243 - acc: 0.4566\n",
      "Epoch 213/500\n",
      "346/346 [==============================] - 0s 82us/step - loss: 1.3212 - acc: 0.4451\n",
      "Epoch 214/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3196 - acc: 0.4538\n",
      "Epoch 215/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3234 - acc: 0.4422\n",
      "Epoch 216/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3224 - acc: 0.4393\n",
      "Epoch 217/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3187 - acc: 0.4653\n",
      "Epoch 218/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3171 - acc: 0.4480\n",
      "Epoch 219/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3147 - acc: 0.4480\n",
      "Epoch 220/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3201 - acc: 0.4451\n",
      "Epoch 221/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3168 - acc: 0.4451\n",
      "Epoch 222/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3165 - acc: 0.4393\n",
      "Epoch 223/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.3181 - acc: 0.4595\n",
      "Epoch 224/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3185 - acc: 0.4393\n",
      "Epoch 225/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3186 - acc: 0.4422\n",
      "Epoch 226/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3134 - acc: 0.4566\n",
      "Epoch 227/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3143 - acc: 0.4509\n",
      "Epoch 228/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3167 - acc: 0.4480\n",
      "Epoch 229/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3139 - acc: 0.4364\n",
      "Epoch 230/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3153 - acc: 0.4480\n",
      "Epoch 231/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3156 - acc: 0.4566\n",
      "Epoch 232/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3132 - acc: 0.4480\n",
      "Epoch 233/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3125 - acc: 0.4451\n",
      "Epoch 234/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3102 - acc: 0.4451\n",
      "Epoch 235/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3117 - acc: 0.4538\n",
      "Epoch 236/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3117 - acc: 0.4451\n",
      "Epoch 237/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3114 - acc: 0.4624\n",
      "Epoch 238/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3092 - acc: 0.4538\n",
      "Epoch 239/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3110 - acc: 0.4451\n",
      "Epoch 240/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3167 - acc: 0.4393\n",
      "Epoch 241/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3113 - acc: 0.4538\n",
      "Epoch 242/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.3105 - acc: 0.4480\n",
      "Epoch 243/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3084 - acc: 0.4624\n",
      "Epoch 244/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.3072 - acc: 0.4624\n",
      "Epoch 245/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3070 - acc: 0.4451\n",
      "Epoch 246/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3108 - acc: 0.4653\n",
      "Epoch 247/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3055 - acc: 0.4653\n",
      "Epoch 248/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3082 - acc: 0.4538\n",
      "Epoch 249/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 89us/step - loss: 1.3058 - acc: 0.4653\n",
      "Epoch 250/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3068 - acc: 0.4538\n",
      "Epoch 251/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3069 - acc: 0.4566\n",
      "Epoch 252/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3056 - acc: 0.4480\n",
      "Epoch 253/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3073 - acc: 0.4566\n",
      "Epoch 254/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3070 - acc: 0.4509\n",
      "Epoch 255/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3048 - acc: 0.4566\n",
      "Epoch 256/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3045 - acc: 0.4509\n",
      "Epoch 257/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3037 - acc: 0.4566\n",
      "Epoch 258/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3037 - acc: 0.4566\n",
      "Epoch 259/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3033 - acc: 0.4566\n",
      "Epoch 260/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3060 - acc: 0.4480\n",
      "Epoch 261/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.3032 - acc: 0.4509\n",
      "Epoch 262/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3025 - acc: 0.4566\n",
      "Epoch 263/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3076 - acc: 0.4509\n",
      "Epoch 264/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.3016 - acc: 0.4682\n",
      "Epoch 265/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3051 - acc: 0.4480\n",
      "Epoch 266/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.3030 - acc: 0.4595\n",
      "Epoch 267/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.3081 - acc: 0.4480\n",
      "Epoch 268/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2993 - acc: 0.4595\n",
      "Epoch 269/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3020 - acc: 0.4624\n",
      "Epoch 270/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3032 - acc: 0.4566\n",
      "Epoch 271/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2999 - acc: 0.4595\n",
      "Epoch 272/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3002 - acc: 0.4509\n",
      "Epoch 273/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3032 - acc: 0.4480\n",
      "Epoch 274/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2984 - acc: 0.4566\n",
      "Epoch 275/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3002 - acc: 0.4538\n",
      "Epoch 276/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.3059 - acc: 0.4451\n",
      "Epoch 277/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2970 - acc: 0.4566\n",
      "Epoch 278/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.3022 - acc: 0.4393\n",
      "Epoch 279/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.3017 - acc: 0.4566\n",
      "Epoch 280/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2994 - acc: 0.4566\n",
      "Epoch 281/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2990 - acc: 0.4538\n",
      "Epoch 282/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2997 - acc: 0.4509\n",
      "Epoch 283/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.3000 - acc: 0.4566\n",
      "Epoch 284/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.2979 - acc: 0.4624\n",
      "Epoch 285/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.3010 - acc: 0.4480\n",
      "Epoch 286/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2965 - acc: 0.4624\n",
      "Epoch 287/500\n",
      "346/346 [==============================] - 0s 106us/step - loss: 1.2960 - acc: 0.4538\n",
      "Epoch 288/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.2978 - acc: 0.4538\n",
      "Epoch 289/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2975 - acc: 0.4509\n",
      "Epoch 290/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2966 - acc: 0.4480\n",
      "Epoch 291/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2964 - acc: 0.4595\n",
      "Epoch 292/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2965 - acc: 0.4653\n",
      "Epoch 293/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.2982 - acc: 0.4566\n",
      "Epoch 294/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2977 - acc: 0.4711\n",
      "Epoch 295/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2943 - acc: 0.4653\n",
      "Epoch 296/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2984 - acc: 0.4538\n",
      "Epoch 297/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2977 - acc: 0.4509\n",
      "Epoch 298/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2976 - acc: 0.4509\n",
      "Epoch 299/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2964 - acc: 0.4566\n",
      "Epoch 300/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2972 - acc: 0.4595\n",
      "Epoch 301/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.3011 - acc: 0.4480\n",
      "Epoch 302/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2924 - acc: 0.4624\n",
      "Epoch 303/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2941 - acc: 0.4624\n",
      "Epoch 304/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2937 - acc: 0.4509\n",
      "Epoch 305/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2937 - acc: 0.4566\n",
      "Epoch 306/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2952 - acc: 0.4538\n",
      "Epoch 307/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2917 - acc: 0.4509\n",
      "Epoch 308/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2940 - acc: 0.4538\n",
      "Epoch 309/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2918 - acc: 0.4538\n",
      "Epoch 310/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2929 - acc: 0.4624\n",
      "Epoch 311/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2920 - acc: 0.4566\n",
      "Epoch 312/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2921 - acc: 0.4624\n",
      "Epoch 313/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2941 - acc: 0.4624\n",
      "Epoch 314/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.2927 - acc: 0.4624\n",
      "Epoch 315/500\n",
      "346/346 [==============================] - 0s 99us/step - loss: 1.2930 - acc: 0.4624\n",
      "Epoch 316/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.2920 - acc: 0.4538\n",
      "Epoch 317/500\n",
      "346/346 [==============================] - 0s 97us/step - loss: 1.2986 - acc: 0.4566\n",
      "Epoch 318/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.2888 - acc: 0.4711\n",
      "Epoch 319/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2917 - acc: 0.4595\n",
      "Epoch 320/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2935 - acc: 0.4566\n",
      "Epoch 321/500\n",
      "346/346 [==============================] - 0s 100us/step - loss: 1.2913 - acc: 0.4624\n",
      "Epoch 322/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2910 - acc: 0.4566\n",
      "Epoch 323/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2913 - acc: 0.4624\n",
      "Epoch 324/500\n",
      "346/346 [==============================] - 0s 101us/step - loss: 1.2903 - acc: 0.4653\n",
      "Epoch 325/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.2928 - acc: 0.4538\n",
      "Epoch 326/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2901 - acc: 0.4624\n",
      "Epoch 327/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.2918 - acc: 0.4595\n",
      "Epoch 328/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2904 - acc: 0.4653\n",
      "Epoch 329/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2909 - acc: 0.4538\n",
      "Epoch 330/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2905 - acc: 0.4566\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 86us/step - loss: 1.2938 - acc: 0.4624\n",
      "Epoch 332/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2893 - acc: 0.4566\n",
      "Epoch 333/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2924 - acc: 0.4480\n",
      "Epoch 334/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2935 - acc: 0.4595\n",
      "Epoch 335/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2889 - acc: 0.4538\n",
      "Epoch 336/500\n",
      "346/346 [==============================] - 0s 82us/step - loss: 1.2891 - acc: 0.4393\n",
      "Epoch 337/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2873 - acc: 0.4566\n",
      "Epoch 338/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2887 - acc: 0.4538\n",
      "Epoch 339/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2868 - acc: 0.4653\n",
      "Epoch 340/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2890 - acc: 0.4624\n",
      "Epoch 341/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2870 - acc: 0.4682\n",
      "Epoch 342/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2927 - acc: 0.4653\n",
      "Epoch 343/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2913 - acc: 0.4595\n",
      "Epoch 344/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2868 - acc: 0.4682\n",
      "Epoch 345/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2901 - acc: 0.4566\n",
      "Epoch 346/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2858 - acc: 0.4653\n",
      "Epoch 347/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.2872 - acc: 0.4566\n",
      "Epoch 348/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.2883 - acc: 0.4480\n",
      "Epoch 349/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2907 - acc: 0.4566\n",
      "Epoch 350/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2836 - acc: 0.4624\n",
      "Epoch 351/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2871 - acc: 0.4509\n",
      "Epoch 352/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2878 - acc: 0.4538\n",
      "Epoch 353/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2856 - acc: 0.4566\n",
      "Epoch 354/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2850 - acc: 0.4624\n",
      "Epoch 355/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2860 - acc: 0.4595\n",
      "Epoch 356/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2858 - acc: 0.4740\n",
      "Epoch 357/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2838 - acc: 0.4711\n",
      "Epoch 358/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2874 - acc: 0.4480\n",
      "Epoch 359/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2844 - acc: 0.4595\n",
      "Epoch 360/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2846 - acc: 0.4595\n",
      "Epoch 361/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2836 - acc: 0.4538\n",
      "Epoch 362/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2873 - acc: 0.4624\n",
      "Epoch 363/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2852 - acc: 0.4653\n",
      "Epoch 364/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2868 - acc: 0.4566\n",
      "Epoch 365/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2831 - acc: 0.4595\n",
      "Epoch 366/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2872 - acc: 0.4653\n",
      "Epoch 367/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2857 - acc: 0.4624\n",
      "Epoch 368/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2826 - acc: 0.4624\n",
      "Epoch 369/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2855 - acc: 0.4624\n",
      "Epoch 370/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2862 - acc: 0.4566\n",
      "Epoch 371/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2877 - acc: 0.4624\n",
      "Epoch 372/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2864 - acc: 0.4566\n",
      "Epoch 373/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2876 - acc: 0.4538\n",
      "Epoch 374/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2831 - acc: 0.4566\n",
      "Epoch 375/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2832 - acc: 0.4566\n",
      "Epoch 376/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2858 - acc: 0.4624\n",
      "Epoch 377/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2824 - acc: 0.4509\n",
      "Epoch 378/500\n",
      "346/346 [==============================] - 0s 82us/step - loss: 1.2836 - acc: 0.4595\n",
      "Epoch 379/500\n",
      "346/346 [==============================] - 0s 82us/step - loss: 1.2826 - acc: 0.4682\n",
      "Epoch 380/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2818 - acc: 0.4653\n",
      "Epoch 381/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2822 - acc: 0.4624\n",
      "Epoch 382/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2818 - acc: 0.4682\n",
      "Epoch 383/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2821 - acc: 0.4595\n",
      "Epoch 384/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2824 - acc: 0.4566\n",
      "Epoch 385/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2816 - acc: 0.4624\n",
      "Epoch 386/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2805 - acc: 0.4653\n",
      "Epoch 387/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2827 - acc: 0.4624\n",
      "Epoch 388/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2803 - acc: 0.4566\n",
      "Epoch 389/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2814 - acc: 0.4538\n",
      "Epoch 390/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2800 - acc: 0.4566\n",
      "Epoch 391/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2842 - acc: 0.4624\n",
      "Epoch 392/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2819 - acc: 0.4624\n",
      "Epoch 393/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2807 - acc: 0.4624\n",
      "Epoch 394/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2805 - acc: 0.4595\n",
      "Epoch 395/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2804 - acc: 0.4740\n",
      "Epoch 396/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2812 - acc: 0.4595\n",
      "Epoch 397/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2842 - acc: 0.4566\n",
      "Epoch 398/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2801 - acc: 0.4682\n",
      "Epoch 399/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2820 - acc: 0.4566\n",
      "Epoch 400/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2827 - acc: 0.4538\n",
      "Epoch 401/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2813 - acc: 0.4624\n",
      "Epoch 402/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2801 - acc: 0.4653\n",
      "Epoch 403/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2797 - acc: 0.4509\n",
      "Epoch 404/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2800 - acc: 0.4624\n",
      "Epoch 405/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2788 - acc: 0.4711\n",
      "Epoch 406/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2804 - acc: 0.4538\n",
      "Epoch 407/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2785 - acc: 0.4595\n",
      "Epoch 408/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2786 - acc: 0.4711\n",
      "Epoch 409/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2801 - acc: 0.4566\n",
      "Epoch 410/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2796 - acc: 0.4595\n",
      "Epoch 411/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2801 - acc: 0.4682\n",
      "Epoch 412/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2761 - acc: 0.4740\n",
      "Epoch 413/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 89us/step - loss: 1.2803 - acc: 0.4595\n",
      "Epoch 414/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2824 - acc: 0.4538\n",
      "Epoch 415/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2829 - acc: 0.4480\n",
      "Epoch 416/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2773 - acc: 0.4711\n",
      "Epoch 417/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2790 - acc: 0.4538\n",
      "Epoch 418/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2827 - acc: 0.4653\n",
      "Epoch 419/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2810 - acc: 0.4595\n",
      "Epoch 420/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2745 - acc: 0.4624\n",
      "Epoch 421/500\n",
      "346/346 [==============================] - 0s 81us/step - loss: 1.2826 - acc: 0.4566\n",
      "Epoch 422/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2798 - acc: 0.4566\n",
      "Epoch 423/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2792 - acc: 0.4653\n",
      "Epoch 424/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2831 - acc: 0.4538\n",
      "Epoch 425/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2816 - acc: 0.4480\n",
      "Epoch 426/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2775 - acc: 0.4624\n",
      "Epoch 427/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2857 - acc: 0.4595\n",
      "Epoch 428/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2834 - acc: 0.4595\n",
      "Epoch 429/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2770 - acc: 0.4624\n",
      "Epoch 430/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2776 - acc: 0.4624\n",
      "Epoch 431/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2771 - acc: 0.4595\n",
      "Epoch 432/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2760 - acc: 0.4653\n",
      "Epoch 433/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2769 - acc: 0.4682\n",
      "Epoch 434/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2765 - acc: 0.4624\n",
      "Epoch 435/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2757 - acc: 0.4538\n",
      "Epoch 436/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2750 - acc: 0.4653\n",
      "Epoch 437/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2761 - acc: 0.4653\n",
      "Epoch 438/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2768 - acc: 0.4566\n",
      "Epoch 439/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2760 - acc: 0.4624\n",
      "Epoch 440/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2792 - acc: 0.4682\n",
      "Epoch 441/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2780 - acc: 0.4538\n",
      "Epoch 442/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2783 - acc: 0.4682\n",
      "Epoch 443/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2771 - acc: 0.4624\n",
      "Epoch 444/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2760 - acc: 0.4595\n",
      "Epoch 445/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2756 - acc: 0.4624\n",
      "Epoch 446/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2765 - acc: 0.4566\n",
      "Epoch 447/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2742 - acc: 0.4682\n",
      "Epoch 448/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2763 - acc: 0.4538\n",
      "Epoch 449/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2747 - acc: 0.4595\n",
      "Epoch 450/500\n",
      "346/346 [==============================] - 0s 89us/step - loss: 1.2768 - acc: 0.4653\n",
      "Epoch 451/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2730 - acc: 0.4653\n",
      "Epoch 452/500\n",
      "346/346 [==============================] - 0s 84us/step - loss: 1.2744 - acc: 0.4624\n",
      "Epoch 453/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2769 - acc: 0.4624\n",
      "Epoch 454/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2823 - acc: 0.4480\n",
      "Epoch 455/500\n",
      "346/346 [==============================] - 0s 83us/step - loss: 1.2745 - acc: 0.4566\n",
      "Epoch 456/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2746 - acc: 0.4769\n",
      "Epoch 457/500\n",
      "346/346 [==============================] - 0s 97us/step - loss: 1.2748 - acc: 0.4566\n",
      "Epoch 458/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2766 - acc: 0.4682\n",
      "Epoch 459/500\n",
      "346/346 [==============================] - 0s 100us/step - loss: 1.2735 - acc: 0.4682\n",
      "Epoch 460/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2749 - acc: 0.4595\n",
      "Epoch 461/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.2732 - acc: 0.4682\n",
      "Epoch 462/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.2753 - acc: 0.4595\n",
      "Epoch 463/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2754 - acc: 0.4653\n",
      "Epoch 464/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.2760 - acc: 0.4595\n",
      "Epoch 465/500\n",
      "346/346 [==============================] - 0s 97us/step - loss: 1.2729 - acc: 0.4653\n",
      "Epoch 466/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.2724 - acc: 0.4538\n",
      "Epoch 467/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2736 - acc: 0.4509\n",
      "Epoch 468/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.2735 - acc: 0.4653\n",
      "Epoch 469/500\n",
      "346/346 [==============================] - 0s 94us/step - loss: 1.2758 - acc: 0.4653\n",
      "Epoch 470/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2727 - acc: 0.4740\n",
      "Epoch 471/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2762 - acc: 0.4480\n",
      "Epoch 472/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2770 - acc: 0.4653\n",
      "Epoch 473/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2751 - acc: 0.4538\n",
      "Epoch 474/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2760 - acc: 0.4595\n",
      "Epoch 475/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2736 - acc: 0.4624\n",
      "Epoch 476/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2719 - acc: 0.4653\n",
      "Epoch 477/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2721 - acc: 0.4653\n",
      "Epoch 478/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.2811 - acc: 0.4653\n",
      "Epoch 479/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2746 - acc: 0.4595\n",
      "Epoch 480/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2717 - acc: 0.4682\n",
      "Epoch 481/500\n",
      "346/346 [==============================] - 0s 92us/step - loss: 1.2718 - acc: 0.4682\n",
      "Epoch 482/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2736 - acc: 0.4653\n",
      "Epoch 483/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2752 - acc: 0.4682\n",
      "Epoch 484/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2750 - acc: 0.4509\n",
      "Epoch 485/500\n",
      "346/346 [==============================] - 0s 85us/step - loss: 1.2733 - acc: 0.4595\n",
      "Epoch 486/500\n",
      "346/346 [==============================] - 0s 86us/step - loss: 1.2744 - acc: 0.4595\n",
      "Epoch 487/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2723 - acc: 0.4624\n",
      "Epoch 488/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2718 - acc: 0.4509\n",
      "Epoch 489/500\n",
      "346/346 [==============================] - 0s 88us/step - loss: 1.2728 - acc: 0.4624\n",
      "Epoch 490/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.2739 - acc: 0.4509\n",
      "Epoch 491/500\n",
      "346/346 [==============================] - 0s 95us/step - loss: 1.2727 - acc: 0.4711\n",
      "Epoch 492/500\n",
      "346/346 [==============================] - 0s 96us/step - loss: 1.2714 - acc: 0.4682\n",
      "Epoch 493/500\n",
      "346/346 [==============================] - 0s 90us/step - loss: 1.2725 - acc: 0.4624\n",
      "Epoch 494/500\n",
      "346/346 [==============================] - 0s 98us/step - loss: 1.2706 - acc: 0.4682\n",
      "Epoch 495/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 0s 92us/step - loss: 1.2712 - acc: 0.4624\n",
      "Epoch 496/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2719 - acc: 0.4480\n",
      "Epoch 497/500\n",
      "346/346 [==============================] - 0s 93us/step - loss: 1.2725 - acc: 0.4653\n",
      "Epoch 498/500\n",
      "346/346 [==============================] - 0s 91us/step - loss: 1.2755 - acc: 0.4538\n",
      "Epoch 499/500\n",
      "346/346 [==============================] - 0s 87us/step - loss: 1.2729 - acc: 0.4538\n",
      "Epoch 500/500\n",
      "346/346 [==============================] - 0s 81us/step - loss: 1.2724 - acc: 0.4653\n",
      "86/86 [==============================] - 0s 572us/step\n",
      "[[0.16302802 0.5778641  0.16884968 0.09025829]\n",
      " [0.12084141 0.4429481  0.30870512 0.12750532]\n",
      " [0.17855981 0.53597033 0.16888437 0.11658546]\n",
      " [0.194393   0.53173804 0.17383176 0.10003731]\n",
      " [0.11297444 0.50884545 0.25623602 0.12194414]\n",
      " [0.20889467 0.4224812  0.24855123 0.12007283]\n",
      " [0.10641503 0.45202097 0.3238846  0.11767939]\n",
      " [0.19282855 0.41392654 0.26093757 0.13230738]\n",
      " [0.32795227 0.39669144 0.14005926 0.13529696]\n",
      " [0.09953754 0.24821247 0.49568406 0.15656595]\n",
      " [0.09970729 0.28650194 0.46990937 0.1438814 ]\n",
      " [0.16323744 0.21357341 0.32023224 0.30295688]\n",
      " [0.10418859 0.4339654  0.33729044 0.12455548]\n",
      " [0.10924872 0.42588866 0.32671136 0.1381512 ]\n",
      " [0.08668005 0.21205047 0.57178    0.1294894 ]\n",
      " [0.10638945 0.43628895 0.33014855 0.12717302]\n",
      " [0.10560711 0.3942779  0.35785183 0.14226308]\n",
      " [0.20430036 0.54503214 0.15587367 0.09479383]\n",
      " [0.14403668 0.46726108 0.27047285 0.1182294 ]\n",
      " [0.24123107 0.50705075 0.14944449 0.10227365]\n",
      " [0.46835855 0.2561427  0.11035327 0.16514547]\n",
      " [0.16332616 0.5544844  0.18022466 0.10196477]\n",
      " [0.08447013 0.2075215  0.58253384 0.12547462]\n",
      " [0.11308203 0.43330657 0.31344256 0.14016886]\n",
      " [0.1670243  0.4398379  0.26678514 0.12635262]\n",
      " [0.18184394 0.5231186  0.18351653 0.11152094]\n",
      " [0.13025877 0.43300995 0.30383477 0.13289657]\n",
      " [0.20402639 0.5220936  0.16884984 0.10503019]\n",
      " [0.10835718 0.59142596 0.20418885 0.09602807]\n",
      " [0.113584   0.46353748 0.31131414 0.11156442]\n",
      " [0.11699834 0.46885914 0.30927485 0.10486771]\n",
      " [0.11731377 0.4256725  0.3221542  0.13485947]\n",
      " [0.20751348 0.49911603 0.17075329 0.12261733]\n",
      " [0.1450392  0.5142925  0.24437498 0.09629331]\n",
      " [0.14849454 0.41497204 0.29862687 0.13790654]\n",
      " [0.276199   0.46331203 0.14646351 0.11402545]\n",
      " [0.32026526 0.40046337 0.13929018 0.13998121]\n",
      " [0.14841357 0.40713626 0.30021945 0.1442307 ]\n",
      " [0.14495876 0.4099544  0.29063988 0.15444702]\n",
      " [0.1609709  0.5639416  0.17215715 0.10293027]\n",
      " [0.10409957 0.31961247 0.42297024 0.15331767]\n",
      " [0.20744047 0.41692513 0.24472758 0.13090676]\n",
      " [0.11418168 0.39771584 0.33063155 0.15747099]\n",
      " [0.2310886  0.45342973 0.16735572 0.14812593]\n",
      " [0.2503504  0.49606648 0.14767492 0.1059082 ]\n",
      " [0.15958914 0.5395678  0.1958104  0.1050326 ]\n",
      " [0.2641709  0.38623497 0.2170767  0.13251738]\n",
      " [0.3452605  0.3833476  0.13567422 0.1357177 ]\n",
      " [0.27336127 0.37753707 0.2125421  0.13655946]\n",
      " [0.18674193 0.5110205  0.19566831 0.10656929]\n",
      " [0.15282147 0.4409345  0.28795648 0.11828759]\n",
      " [0.24704666 0.40144867 0.22621816 0.12528642]\n",
      " [0.11006371 0.4508792  0.31862366 0.12043342]\n",
      " [0.16399401 0.2488888  0.30032167 0.28679547]\n",
      " [0.19109623 0.42757845 0.26009044 0.12123474]\n",
      " [0.23366642 0.40823266 0.2341986  0.12390224]\n",
      " [0.28898093 0.43311456 0.14662789 0.1312766 ]\n",
      " [0.1637648  0.43415818 0.28084338 0.12123361]\n",
      " [0.1849974  0.5210114  0.17250216 0.1214891 ]\n",
      " [0.13326226 0.45158395 0.3020669  0.11308696]\n",
      " [0.11346698 0.41890192 0.3263056  0.14132555]\n",
      " [0.31596434 0.4168992  0.14079781 0.1263386 ]\n",
      " [0.2755077  0.46353465 0.14680582 0.11415175]\n",
      " [0.10946376 0.35580304 0.36930367 0.16542953]\n",
      " [0.4066787  0.1310558  0.13713378 0.3251317 ]\n",
      " [0.09473095 0.2538754  0.5085595  0.14283414]\n",
      " [0.08806513 0.21900629 0.56058437 0.13234416]\n",
      " [0.10585156 0.4299476  0.33474335 0.12945756]\n",
      " [0.26108858 0.4216743  0.16468987 0.15254727]\n",
      " [0.22706807 0.20645028 0.22980826 0.33667338]\n",
      " [0.10038728 0.28973475 0.4612043  0.14867362]\n",
      " [0.1110061  0.535092   0.24405123 0.10985066]\n",
      " [0.19964413 0.53484976 0.16757584 0.09793024]\n",
      " [0.17522869 0.58659774 0.13876763 0.09940594]\n",
      " [0.22257712 0.51685166 0.14520678 0.11536448]\n",
      " [0.12118626 0.46139628 0.31129277 0.10612471]\n",
      " [0.08578923 0.21200377 0.57436126 0.12784576]\n",
      " [0.11838032 0.50320977 0.2466411  0.13176873]\n",
      " [0.1062233  0.3941869  0.35415995 0.14542982]\n",
      " [0.19476053 0.562813   0.14893657 0.09348994]\n",
      " [0.28614607 0.3700637  0.20768529 0.13610503]\n",
      " [0.10422052 0.44134519 0.33298185 0.12145249]\n",
      " [0.13221723 0.49163675 0.26934764 0.10679842]\n",
      " [0.10701415 0.47458732 0.30601743 0.1123811 ]\n",
      " [0.13179722 0.44761577 0.3037202  0.11686678]\n",
      " [0.23242177 0.5128898  0.13842763 0.11626079]]\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "[1.3671777442444202, 0.3837209319652513]\n",
      "[1.3671777442444202, 0.3837209319652513]\n"
     ]
    }
   ],
   "source": [
    "print (nn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nothing': {'count': 60, 'avg': -0.1495163101219509}, 'easy': {'avg': -0.3228843698277435, 'count': 142}, 'medium': {'avg': -0.1451729862855142, 'count': 97}, 'hard': {'avg': -0.2366551080729964, 'count': 47}}\n",
      "based on productivity: \n",
      "peope who rank between -2 and -1 (least productive): \n",
      "{'nothing': 31.11111111111111, 'easy': 37.77777777777778, 'medium': 20.0, 'hard': 11.11111111111111, 'count': 45}\n",
      "people who rank between -1 and 0:\n",
      "{'nothing': 13.043478260869565, 'easy': 45.108695652173914, 'medium': 27.173913043478258, 'hard': 14.67391304347826, 'count': 184}\n",
      "people who rank between 0 and 1:\n",
      "{'nothing': 21.21212121212121, 'easy': 37.37373737373738, 'medium': 29.292929292929294, 'hard': 12.121212121212121, 'count': 99}\n",
      "people who rank between 1 and 2:\n",
      "{'nothing': 5.555555555555555, 'easy': 27.77777777777778, 'medium': 50.0, 'hard': 16.666666666666668, 'count': 18}\n"
     ]
    }
   ],
   "source": [
    "stats = {'nothing': {'count': 0, 'avg':0}, 'easy' : {'avg': 0, 'count': 0}, 'medium' : {'avg': 0, 'count': 0},\n",
    "         'hard' : {'avg': 0, 'count': 0}}\n",
    "users = [{'nothing': 0, 'easy': 0, 'medium': 0, 'hard': 0, 'count': 0}, \n",
    "       {'nothing': 0, 'easy': 0, 'medium': 0, 'hard': 0, 'count': 0}, \n",
    "       {'nothing': 0, 'easy': 0, 'medium': 0, 'hard': 0, 'count': 0}, \n",
    "       {'nothing': 0, 'easy': 0, 'medium': 0, 'hard': 0, 'count': 0}]\n",
    "\n",
    "for line in training_data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    cnt = 0\n",
    "    sm = 0\n",
    "    domains = get_all_domains()\n",
    "    final_features = [0, 0, 0, 0, 0];\n",
    "    for x in domains:\n",
    "        if x in domain_to_productivity.keys():\n",
    "            sm += domain_to_productivity[x] * get_num_visits_for_domain(domain_visit_info, x)\n",
    "            cnt += get_num_visits_for_domain(domain_visit_info, x)\n",
    "    sm /= cnt\n",
    "    #print(sm)\n",
    "    stats[line['selected_difficulty']]['count'] += 1\n",
    "    stats[line['selected_difficulty']]['avg'] += sm\n",
    "    if sm >= 1: \n",
    "        users[3][line['selected_difficulty']] += 1\n",
    "        users[3]['count'] += 1\n",
    "    elif sm >= 0: \n",
    "        users[2][line['selected_difficulty']] += 1\n",
    "        users[2]['count'] += 1\n",
    "    elif sm >= -1:\n",
    "        users[1][line['selected_difficulty']] += 1\n",
    "        users[1]['count'] += 1\n",
    "    else: \n",
    "        users[0][line['selected_difficulty']] += 1\n",
    "        users[0]['count'] += 1\n",
    "     \n",
    "    #hard medium easy nothing \n",
    "stats['hard']['avg'] /= stats['hard']['count']\n",
    "stats['medium']['avg'] /= stats['medium']['count']\n",
    "stats['easy']['avg'] /= stats['easy']['count']\n",
    "stats['nothing']['avg'] /= stats['easy']['count']\n",
    "for i in range(-2, 2):\n",
    "    users[i + 2]['nothing'] /= users[i + 2]['count'] / 100\n",
    "    users[i + 2]['easy'] /= users[i + 2]['count'] / 100\n",
    "    users[i + 2]['medium'] /= users[i + 2]['count'] / 100\n",
    "    users[i + 2]['hard'] /= users[i + 2]['count'] / 100\n",
    "\n",
    "print(stats)\n",
    "print (\"based on productivity: \")\n",
    "print (\"peope who rank between -2 and -1 (least productive): \")\n",
    "print (users[0])\n",
    "\n",
    "print (\"people who rank between -1 and 0:\")\n",
    "print (users[1])\n",
    "\n",
    "print (\"people who rank between 0 and 1:\")\n",
    "print (users[2])\n",
    "print (\"people who rank between 1 and 2:\")\n",
    "print (users[3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
