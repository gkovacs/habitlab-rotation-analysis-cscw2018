{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import lzstring\n",
    "from collections import namedtuple, Counter\n",
    "import json\n",
    "from memoize import memoize\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# [num unique urls, num unique urls typed, total visits, total typed, first visit time, last visit time]\n",
    "domaininfo = namedtuple('domaininfo', ['num_unique_urls', 'num_unique_urls_typed', 'total_visits', 'total_typed', 'first_visit_time', 'last_visit_time'])\n",
    "\n",
    "decompressFromEncodedURIComponent = lzstring.LZString().decompressFromEncodedURIComponent\n",
    "\n",
    "#filepath = 'difficultyselectionexp_may31_11am.csv'\n",
    "filepath = 'data/difficultyselectionexp_june25_9pm.csv'\n",
    "reader = csv.DictReader(open(filepath))\n",
    "\n",
    "def extract_domain_visit_info(domain_visit_info_compressed):\n",
    "  domain_visit_info = json.loads(decompressFromEncodedURIComponent(domain_visit_info_compressed))\n",
    "  output = {}\n",
    "  for k,v in domain_visit_info.items():\n",
    "    linedata = domaininfo(*v)\n",
    "    output[k] = linedata\n",
    "  return output\n",
    "\n",
    "alldata = []\n",
    "\n",
    "for alldata_item in reader:\n",
    "  if alldata_item['selected_difficulty'] not in ['nothing', 'easy', 'medium', 'hard']:\n",
    "    continue\n",
    "  if alldata_item['domain_visit_info_compressed'] == None or len(alldata_item['domain_visit_info_compressed']) == 0:\n",
    "    continue\n",
    "  alldata_item['domain_visit_info'] = extract_domain_visit_info(alldata_item['domain_visit_info_compressed'])\n",
    "  alldata.append(alldata_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "#np.random.shuffle(alldata)\n",
    "training_data = alldata[:round(len(alldata)*0.8)]\n",
    "test_data = alldata[round(len(alldata)*0.8):]\n",
    "print(len(training_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_alldata(data):\n",
    "  return np.array([line['selected_difficulty'] for line in data])\n",
    "\n",
    "@memoize\n",
    "def get_most_common_label():\n",
    "  label_to_count = Counter()\n",
    "  for line in training_data:\n",
    "    label = line['selected_difficulty']\n",
    "    label_to_count[label] += 1\n",
    "  sorted_by_count = sorted(label_to_count.items(), key=lambda x: x[1], reverse=True)\n",
    "  return sorted_by_count[0][0]\n",
    "\n",
    "@memoize\n",
    "def get_most_visited_domains():\n",
    "  domain_to_num_visits = Counter()\n",
    "  for line in training_data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    for domain,info in domain_visit_info.items():\n",
    "      domain_to_num_visits[domain] += info.total_visits\n",
    "  sorted_by_num_visits = sorted(domain_to_num_visits.items(), key=lambda x: x[1], reverse=True)\n",
    "  return [x[0] for x in sorted_by_num_visits[:100]]\n",
    "\n",
    "cnt = 0\n",
    "@memoize\n",
    "def get_most_common_domains():\n",
    "  domain_to_num_visits = Counter()\n",
    "  for line in training_data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    for domain,info in domain_visit_info.items():\n",
    "      domain_to_num_visits[domain] += 1\n",
    "  sorted_by_num_visits = sorted(domain_to_num_visits.items(), key=lambda x: x[1], reverse=True)\n",
    "  return [x[0] for x in sorted_by_num_visits[:100]]\n",
    "\n",
    "def get_all_domains():\n",
    "  domain_to_num_visits = Counter()\n",
    "  for line in training_data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    for domain,info in domain_visit_info.items():\n",
    "      domain_to_num_visits[domain] += 1\n",
    "  sorted_by_num_visits = sorted(domain_to_num_visits.items(), key=lambda x: x[1], reverse=True)\n",
    "  return [x[0] for x in sorted_by_num_visits]\n",
    "\n",
    "\n",
    "\n",
    "def get_num_visits_for_domain(domain_visit_info, domain):\n",
    "  info = domain_visit_info.get(domain, None)\n",
    "  if info != None:\n",
    "    return info.total_visits\n",
    "  return 0\n",
    "\n",
    "def get_productivity():\n",
    "    with open ('domain_to_productivity.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        return data\n",
    "\n",
    "domain_to_productivity = get_productivity()\n",
    "\n",
    "def extract_features_for_user(domain_visit_info):\n",
    "  cnt = 0\n",
    "  domains = get_all_domains()\n",
    "  final_features = [0, 0, 0, 0, 0];\n",
    "  for x in domains:\n",
    "        if x in domain_to_productivity.keys():\n",
    "            final_features[domain_to_productivity[x] + 2] += get_num_visits_for_domain(domain_visit_info, x)\n",
    "    \n",
    "  #np.array([get_num_visits_for_domain(domain_visit_info, x) for x in domains])\n",
    "  if np.sum(final_features) >= 1:\n",
    "    final_features = np.divide(final_features, np.sum(final_features))\n",
    "  return final_features\n",
    "\n",
    "def extract_features_alldata(data):\n",
    "  output = []\n",
    "  for line in data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    features = extract_features_for_user(domain_visit_info)\n",
    "    output.append(features)\n",
    "  return np.array(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline classifier accuracy: 0.4186046511627907\n"
     ]
    }
   ],
   "source": [
    "def get_percent_correct(predicted_labels, actual_labels):\n",
    "  if len(predicted_labels) != len(actual_labels):\n",
    "    raise 'need predicted and actual labels to have same lengths'\n",
    "  total = len(actual_labels)\n",
    "  correct = 0\n",
    "  for p,a in zip(predicted_labels, actual_labels):\n",
    "    if p == a:\n",
    "      correct += 1\n",
    "  return correct / total\n",
    "\n",
    "def test_baseline_classifier():\n",
    "  most_common_label = get_most_common_label()\n",
    "  predictions = [most_common_label for line in test_data]\n",
    "  actual = extract_labels_alldata(test_data)\n",
    "  percent_correct = get_percent_correct(predictions, actual)\n",
    "  print('baseline classifier accuracy:', percent_correct)\n",
    "\n",
    "def test_classifier(clf,features_test, actual, str=None):\n",
    "  #actual = extract_labels_alldata(test_data)\n",
    "  #features_test = extract_features_alldata(test_data)\n",
    "  predictions = clf.predict(features_test)\n",
    "  percent_correct = get_percent_correct(predictions, actual)\n",
    "  return percent_correct\n",
    "\n",
    "def training_error_classifier(clf, str=None):\n",
    "  actual = extract_labels_alldata(training_data)\n",
    "  features_train = extract_features_alldata(training_data)\n",
    "  predictions = clf.predict(features_train)\n",
    "  percent_correct = get_percent_correct(predictions, actual)\n",
    "  print(str + ' classifier training accuracy:', round(percent_correct, 2))\n",
    "\n",
    "def to_int_categorical(dt):\n",
    "  # {'easy', 'hard', 'medium', 'nothing'}\n",
    "  cat_dt = []\n",
    "  for item in dt:\n",
    "    if item == 'nothing':\n",
    "      cat_dt.append(0)\n",
    "    elif item == 'easy':\n",
    "      cat_dt.append(1)\n",
    "    elif item == 'medium':\n",
    "      cat_dt.append(2)\n",
    "    else:\n",
    "      cat_dt.append(3)\n",
    "  return np.array(cat_dt)\n",
    "    \n",
    "test_baseline_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "\n",
    "labels_test = to_categorical(to_int_categorical(extract_labels_alldata(test_data)), num_classes=4)\n",
    "features_test = extract_features_alldata(test_data)\n",
    "\n",
    "labels_train = to_categorical(to_int_categorical(extract_labels_alldata(training_data)), num_classes=4)\n",
    "features_train = extract_features_alldata(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nothing': {'count': 60, 'avg': -0.1495163101219509}, 'easy': {'avg': -0.3228843698277435, 'count': 142}, 'medium': {'avg': -0.1451729862855142, 'count': 97}, 'hard': {'avg': -0.2366551080729964, 'count': 47}}\n",
      "based on productivity: \n",
      "peope who rank between -2 and -1 (least productive): \n",
      "{'nothing': 31.11111111111111, 'easy': 37.77777777777778, 'medium': 20.0, 'hard': 11.11111111111111, 'count': 45}\n",
      "people who rank between -1 and 0:\n",
      "{'nothing': 13.043478260869565, 'easy': 45.108695652173914, 'medium': 27.173913043478258, 'hard': 14.67391304347826, 'count': 184}\n",
      "people who rank between 0 and 1:\n",
      "{'nothing': 21.21212121212121, 'easy': 37.37373737373738, 'medium': 29.292929292929294, 'hard': 12.121212121212121, 'count': 99}\n",
      "people who rank between 1 and 2:\n",
      "{'nothing': 5.555555555555555, 'easy': 27.77777777777778, 'medium': 50.0, 'hard': 16.666666666666668, 'count': 18}\n"
     ]
    }
   ],
   "source": [
    "stats = {'nothing': {'count': 0, 'avg':0}, 'easy' : {'avg': 0, 'count': 0}, 'medium' : {'avg': 0, 'count': 0},\n",
    "         'hard' : {'avg': 0, 'count': 0}}\n",
    "users = [{'nothing': 0, 'easy': 0, 'medium': 0, 'hard': 0, 'count': 0}, \n",
    "       {'nothing': 0, 'easy': 0, 'medium': 0, 'hard': 0, 'count': 0}, \n",
    "       {'nothing': 0, 'easy': 0, 'medium': 0, 'hard': 0, 'count': 0}, \n",
    "       {'nothing': 0, 'easy': 0, 'medium': 0, 'hard': 0, 'count': 0}]\n",
    "\n",
    "for line in training_data:\n",
    "    domain_visit_info = line['domain_visit_info']\n",
    "    cnt = 0\n",
    "    sm = 0\n",
    "    domains = get_all_domains()\n",
    "    final_features = [0, 0, 0, 0, 0];\n",
    "    for x in domains:\n",
    "        if x in domain_to_productivity.keys():\n",
    "            sm += domain_to_productivity[x] * get_num_visits_for_domain(domain_visit_info, x)\n",
    "            cnt += get_num_visits_for_domain(domain_visit_info, x)\n",
    "    sm /= cnt\n",
    "    #print(sm)\n",
    "    stats[line['selected_difficulty']]['count'] += 1\n",
    "    stats[line['selected_difficulty']]['avg'] += sm\n",
    "    if sm >= 1: \n",
    "        users[3][line['selected_difficulty']] += 1\n",
    "        users[3]['count'] += 1\n",
    "    elif sm >= 0: \n",
    "        users[2][line['selected_difficulty']] += 1\n",
    "        users[2]['count'] += 1\n",
    "    elif sm >= -1:\n",
    "        users[1][line['selected_difficulty']] += 1\n",
    "        users[1]['count'] += 1\n",
    "    else: \n",
    "        users[0][line['selected_difficulty']] += 1\n",
    "        users[0]['count'] += 1\n",
    "     \n",
    "    #hard medium easy nothing \n",
    "stats['hard']['avg'] /= stats['hard']['count']\n",
    "stats['medium']['avg'] /= stats['medium']['count']\n",
    "stats['easy']['avg'] /= stats['easy']['count']\n",
    "stats['nothing']['avg'] /= stats['easy']['count']\n",
    "for i in range(-2, 2):\n",
    "    users[i + 2]['nothing'] /= users[i + 2]['count'] / 100\n",
    "    users[i + 2]['easy'] /= users[i + 2]['count'] / 100\n",
    "    users[i + 2]['medium'] /= users[i + 2]['count'] / 100\n",
    "    users[i + 2]['hard'] /= users[i + 2]['count'] / 100\n",
    "\n",
    "print(stats)\n",
    "print (\"based on productivity: \")\n",
    "print (\"peope who rank between -2 and -1 (least productive): \")\n",
    "print (users[0])\n",
    "\n",
    "print (\"people who rank between -1 and 0:\")\n",
    "print (users[1])\n",
    "\n",
    "print (\"people who rank between 0 and 1:\")\n",
    "print (users[2])\n",
    "print (\"people who rank between 1 and 2:\")\n",
    "print (users[3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
